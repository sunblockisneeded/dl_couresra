{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lr_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고양이인 데이터와 고양이가 아닌 데이터를\n",
    "# 로지스틱 회귀를 통해 구분해보기\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils -param 시작, sigmoid\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    #zeros, ones는 zeros((차원1, 차원2))과 같은식으로 사용해야 함\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0.\n",
    "    return w, b\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w ,b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    Z = w.T@X + b\n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    cost = (Y * np.log(A) + (1-Y) * np.log(1-A)).sum() / -m\n",
    "\n",
    "    dw = (X @ (A-Y).T) / m\n",
    "    db = (A-Y).sum() / m\n",
    "    grads = {\n",
    "        \"dw\" : dw,\n",
    "        \"db\" : db,\n",
    "    }\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations = 2000, lr = 0.009, print_cost = True):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        #update param\n",
    "        #deepcopy를 사용하지 않는다면 optimize 외부에서 넘어온 w와 b의 값이\n",
    "        #어딘가에서 변할 수도 있음\n",
    "        w = w- lr * dw\n",
    "        b = b- lr * db\n",
    "        \n",
    "        if (i+1) % 100 ==0:\n",
    "            costs.append(cost)\n",
    "\n",
    "            if print_cost:\n",
    "                print(f\"Cost After {i+1} iterations : {cost}\")\n",
    "    params = {\n",
    "        \"w\" : w, \n",
    "        \"b\" : b}\n",
    "    \n",
    "    grads = {\"dw\" : dw,\n",
    "             \"db\" : db,}\n",
    "    return params, grads, costs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost After 100 iterations : 0.47715649504824453\n",
      "Cost After 200 iterations : 0.8471092191546921\n",
      "Cost After 300 iterations : 0.5837524449397078\n",
      "Cost After 400 iterations : 0.48113380121374033\n",
      "Cost After 500 iterations : 0.36121067514479355\n",
      "Cost After 600 iterations : 0.24121803161715624\n",
      "Cost After 700 iterations : 0.16856909780439225\n",
      "Cost After 800 iterations : 0.15051961104077807\n",
      "Cost After 900 iterations : 0.13960214924932912\n",
      "Cost After 1000 iterations : 0.1303981662836805\n",
      "Cost After 1100 iterations : 0.1223950112584566\n",
      "Cost After 1200 iterations : 0.11532321915155781\n",
      "Cost After 1300 iterations : 0.10901077034429985\n",
      "Cost After 1400 iterations : 0.10333458691721242\n",
      "Cost After 1500 iterations : 0.0982005870101832\n",
      "Cost After 1600 iterations : 0.09353397980325093\n",
      "Cost After 1700 iterations : 0.08927382998229712\n",
      "Cost After 1800 iterations : 0.08536965873672563\n",
      "Cost After 1900 iterations : 0.0817791391225479\n",
      "Cost After 2000 iterations : 0.07846644198882445\n"
     ]
    }
   ],
   "source": [
    "train_set_x = train_set_x_flatten / train_set_x_flatten.max()\n",
    "test_set_x = test_set_x_flatten / train_set_x_flatten.max() # 흠 스케일링을 똑같이 해야겠죠?\n",
    "w,b = initialize_with_zeros(train_set_x.shape[0])\n",
    "params, grads, costs = optimize(w,b,train_set_x,train_set_y, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,X):\n",
    "    m = X.shape[1]\n",
    "    #y와 같은 차원으로 일단 배열을 만들어. 다 False인 상태\n",
    "    Y_pred = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(w.T@X + b)\n",
    "    #dataset의 갯수만큼\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0,i] > 0.5:\n",
    "            Y_pred[0,i] = 1.\n",
    "        else:\n",
    "            Y_pred[0,i] = 0. #어차피 0으로 초기화되어있으니 안 써도 됨\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 모델에 모두 통합해보기\n",
    "# 모델의 input은train_x,y / test_x,y \n",
    "# 모델의 output은 여러 결과들일 거임\n",
    "# 그 결과는 cost, prediction accuracy가 되겠죠?\n",
    "# 경우에 따라서 w,b등의 파라미터도 output으로 나올 수 있을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. parameters initialize 하기\n",
    "2. optimize를 통해서 params, grads, costs 산출하기\n",
    "3. 산출한 params를 활용해서 predict하기\n",
    "4. predict한 결과를 train에서와 test에서 비교해보며 분석해보기\n",
    "'''\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations= 2000, lr= 0.09, print_cost = True, print_acc = True):\n",
    "    '''\n",
    "    dataset은 (-1, m) 형태로 flatten 되어있어야 하며\n",
    "    사진과 같은 픽셀에서는 /255로 나눈 뒤에 집어넣어줘야 합니다.\n",
    "    '''\n",
    "    #prams 0으로 초기설정\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    params, grads, costs = optimize(w ,b ,X_train ,Y_train, num_iterations, lr,print_cost) \n",
    "    w = params.get(\"w\")\n",
    "    b = params.get(\"b\")\n",
    "\n",
    "    #w와 b가 확보되었으니, 확보된 w와 b를 활용해 train과 test에서 prediction해보기\n",
    "    Y_pred_train = predict(w,b,X_train)\n",
    "    Y_pred_test = predict(w,b,X_test)\n",
    "\n",
    "    #print cost 옵션이 True라면 cost를 출력\n",
    "    if print_acc:\n",
    "        train_acc = (1 - np.mean(np.abs(Y_pred_train - Y_train))) * 100\n",
    "        test_acc = (1 - np.mean(np.abs(Y_pred_test - Y_test))) * 100\n",
    "        print(f\"train_acc : {train_acc}%\")\n",
    "        print(f\"test_acc : {test_acc}%\")\n",
    "    \n",
    "\n",
    "    d = {\"costs\" : costs,\n",
    "         \"w\" : w,\n",
    "         \"b\" : b,\n",
    "         \"lr\" : lr\n",
    "         }\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#자 이제 실제로 데이터를 모델에 넣는 시뮬레이션을 해봅시다!\n",
    "#load dataset\n",
    "X_train_orig, Y_train, X_test_orig, Y_test, classes = load_dataset() #class는 뭐하는건지 잘 모르겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 64, 64, 3)\n",
      "(1, 209)\n"
     ]
    }
   ],
   "source": [
    "#x와 y가 어떻게 생겼는지 개략적으로 파악\n",
    "print(X_train_orig.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 17,  31,  56],\n",
       "         [ 22,  33,  59],\n",
       "         [ 25,  35,  62],\n",
       "         ...,\n",
       "         [  1,  28,  57],\n",
       "         [  1,  26,  56],\n",
       "         [  1,  22,  51]],\n",
       "\n",
       "        [[ 25,  36,  62],\n",
       "         [ 28,  38,  64],\n",
       "         [ 30,  40,  67],\n",
       "         ...,\n",
       "         [  1,  27,  56],\n",
       "         [  1,  25,  55],\n",
       "         [  2,  21,  51]],\n",
       "\n",
       "        [[ 32,  40,  67],\n",
       "         [ 34,  42,  69],\n",
       "         [ 35,  42,  70],\n",
       "         ...,\n",
       "         [  1,  25,  55],\n",
       "         [  0,  24,  54],\n",
       "         [  1,  21,  51]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]],\n",
       "\n",
       "\n",
       "       [[[196, 192, 190],\n",
       "         [193, 186, 182],\n",
       "         [188, 179, 174],\n",
       "         ...,\n",
       "         [ 90, 142, 200],\n",
       "         [ 90, 142, 201],\n",
       "         [ 90, 142, 201]],\n",
       "\n",
       "        [[230, 229, 229],\n",
       "         [204, 199, 197],\n",
       "         [193, 186, 181],\n",
       "         ...,\n",
       "         [ 91, 143, 201],\n",
       "         [ 91, 143, 201],\n",
       "         [ 91, 143, 201]],\n",
       "\n",
       "        [[232, 225, 224],\n",
       "         [235, 234, 234],\n",
       "         [208, 205, 202],\n",
       "         ...,\n",
       "         [ 91, 144, 202],\n",
       "         [ 91, 144, 202],\n",
       "         [ 92, 144, 202]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 18,  17,  15],\n",
       "         [ 14,  14,  13],\n",
       "         [ 29,  29,  32],\n",
       "         ...,\n",
       "         [ 83,  81,  81],\n",
       "         [ 84,  82,  83],\n",
       "         [ 82,  81,  82]],\n",
       "\n",
       "        [[ 22,  20,  18],\n",
       "         [ 16,  15,  14],\n",
       "         [ 25,  24,  24],\n",
       "         ...,\n",
       "         [ 82,  80,  80],\n",
       "         [ 83,  81,  82],\n",
       "         [ 82,  81,  81]],\n",
       "\n",
       "        [[ 45,  43,  39],\n",
       "         [ 61,  59,  54],\n",
       "         [ 81,  78,  74],\n",
       "         ...,\n",
       "         [ 83,  82,  81],\n",
       "         [ 84,  82,  82],\n",
       "         [ 82,  80,  81]]],\n",
       "\n",
       "\n",
       "       [[[ 82,  71,  68],\n",
       "         [ 89,  83,  83],\n",
       "         [100,  98, 104],\n",
       "         ...,\n",
       "         [131, 132, 137],\n",
       "         [126, 124, 124],\n",
       "         [105,  97,  95]],\n",
       "\n",
       "        [[ 95,  91,  97],\n",
       "         [104, 104, 113],\n",
       "         [110, 115, 126],\n",
       "         ...,\n",
       "         [135, 134, 135],\n",
       "         [127, 122, 119],\n",
       "         [111, 105, 103]],\n",
       "\n",
       "        [[ 94,  85,  83],\n",
       "         [ 97,  89,  90],\n",
       "         [110, 109, 115],\n",
       "         ...,\n",
       "         [136, 134, 131],\n",
       "         [127, 120, 117],\n",
       "         [116, 108, 104]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 96, 116, 131],\n",
       "         [ 97, 115, 130],\n",
       "         [103, 123, 139],\n",
       "         ...,\n",
       "         [152, 155, 157],\n",
       "         [146, 149, 152],\n",
       "         [130, 133, 134]],\n",
       "\n",
       "        [[ 90, 108, 123],\n",
       "         [ 92, 108, 121],\n",
       "         [100, 119, 134],\n",
       "         ...,\n",
       "         [150, 152, 155],\n",
       "         [144, 146, 147],\n",
       "         [134, 135, 134]],\n",
       "\n",
       "        [[ 86, 102, 116],\n",
       "         [ 87, 103, 115],\n",
       "         [ 94, 114, 127],\n",
       "         ...,\n",
       "         [154, 156, 160],\n",
       "         [146, 148, 152],\n",
       "         [138, 141, 142]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[143, 155, 165],\n",
       "         [184, 190, 198],\n",
       "         [142, 149, 155],\n",
       "         ...,\n",
       "         [ 99,  92, 102],\n",
       "         [120,  98, 102],\n",
       "         [100,  84,  95]],\n",
       "\n",
       "        [[151, 149, 139],\n",
       "         [173, 179, 185],\n",
       "         [105, 135, 141],\n",
       "         ...,\n",
       "         [ 91,  87,  99],\n",
       "         [119,  99, 104],\n",
       "         [120,  95, 101]],\n",
       "\n",
       "        [[204, 190, 185],\n",
       "         [180, 185, 195],\n",
       "         [117, 155, 177],\n",
       "         ...,\n",
       "         [ 96,  88, 101],\n",
       "         [125, 103, 110],\n",
       "         [120, 100, 110]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 41,  80, 116],\n",
       "         [ 41,  80, 116],\n",
       "         [ 41,  78, 115],\n",
       "         ...,\n",
       "         [ 63,  75,  98],\n",
       "         [ 60,  72,  98],\n",
       "         [ 60,  70,  96]],\n",
       "\n",
       "        [[ 71,  90, 121],\n",
       "         [ 73,  91, 123],\n",
       "         [ 74,  91, 124],\n",
       "         ...,\n",
       "         [ 79, 101, 142],\n",
       "         [ 80, 100, 140],\n",
       "         [ 82, 101, 139]],\n",
       "\n",
       "        [[ 71,  88, 122],\n",
       "         [ 73,  92, 128],\n",
       "         [ 76,  95, 131],\n",
       "         ...,\n",
       "         [ 81, 106, 150],\n",
       "         [ 85, 108, 151],\n",
       "         [ 85, 107, 149]]],\n",
       "\n",
       "\n",
       "       [[[ 22,  24,  23],\n",
       "         [ 23,  25,  24],\n",
       "         [ 24,  26,  25],\n",
       "         ...,\n",
       "         [ 24,  29,  25],\n",
       "         [ 23,  25,  22],\n",
       "         [ 20,  22,  21]],\n",
       "\n",
       "        [[ 22,  24,  23],\n",
       "         [ 23,  25,  24],\n",
       "         [ 23,  26,  25],\n",
       "         ...,\n",
       "         [ 22,  28,  23],\n",
       "         [ 20,  23,  22],\n",
       "         [ 19,  21,  21]],\n",
       "\n",
       "        [[ 22,  24,  22],\n",
       "         [ 23,  25,  24],\n",
       "         [ 23,  26,  25],\n",
       "         ...,\n",
       "         [ 23,  27,  23],\n",
       "         [ 20,  23,  21],\n",
       "         [ 18,  20,  19]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  8,   5,   0],\n",
       "         [  9,   6,   1],\n",
       "         [  9,   6,   1],\n",
       "         ...,\n",
       "         [  4,   5,   0],\n",
       "         [  5,   4,   0],\n",
       "         [  4,   5,   0]],\n",
       "\n",
       "        [[  7,   5,   0],\n",
       "         [  8,   5,   1],\n",
       "         [  9,   6,   1],\n",
       "         ...,\n",
       "         [  4,   5,   0],\n",
       "         [  4,   5,   0],\n",
       "         [  4,   5,   0]],\n",
       "\n",
       "        [[  7,   5,   0],\n",
       "         [  8,   5,   0],\n",
       "         [  9,   6,   1],\n",
       "         ...,\n",
       "         [  4,   5,   0],\n",
       "         [  4,   5,   0],\n",
       "         [  4,   5,   0]]],\n",
       "\n",
       "\n",
       "       [[[  8,  28,  53],\n",
       "         [ 14,  33,  58],\n",
       "         [ 19,  35,  61],\n",
       "         ...,\n",
       "         [ 11,  16,  35],\n",
       "         [ 10,  16,  35],\n",
       "         [  9,  14,  32]],\n",
       "\n",
       "        [[ 15,  31,  57],\n",
       "         [ 15,  32,  58],\n",
       "         [ 18,  34,  60],\n",
       "         ...,\n",
       "         [ 13,  17,  35],\n",
       "         [ 13,  17,  35],\n",
       "         [ 13,  16,  35]],\n",
       "\n",
       "        [[ 20,  35,  61],\n",
       "         [ 19,  33,  59],\n",
       "         [ 20,  33,  59],\n",
       "         ...,\n",
       "         [ 16,  17,  35],\n",
       "         [ 16,  18,  35],\n",
       "         [ 15,  17,  35]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x와 y가 구체적으로 어떻게 생겼는지 파악\n",
    "display(X_train_orig)\n",
    "display(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 요구사항에 맞춰서 데이터 전처리\n",
    "X_train = X_train_orig.reshape(X_train_orig.shape[0], -1).T / 255.\n",
    "X_test = X_test_orig.reshape(X_test_orig.shape[0], -1).T / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Temp\\ipykernel_13296\\2598877797.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (Y * np.log(A) + (1-Y) * np.log(1-A)).sum() / -m\n",
      "C:\\Users\\eddie\\AppData\\Local\\Temp\\ipykernel_13296\\2598877797.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (Y * np.log(A) + (1-Y) * np.log(1-A)).sum() / -m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost After 100 iterations : 9.634550539428096\n",
      "Cost After 200 iterations : 9.189480639570984\n",
      "Cost After 300 iterations : 0.7335429872619103\n",
      "Cost After 400 iterations : nan\n",
      "Cost After 500 iterations : nan\n",
      "Cost After 600 iterations : nan\n",
      "Cost After 700 iterations : nan\n",
      "Cost After 800 iterations : nan\n",
      "Cost After 900 iterations : nan\n",
      "Cost After 1000 iterations : nan\n",
      "Cost After 1100 iterations : nan\n",
      "Cost After 1200 iterations : nan\n",
      "Cost After 1300 iterations : nan\n",
      "Cost After 1400 iterations : nan\n",
      "Cost After 1500 iterations : nan\n",
      "Cost After 1600 iterations : nan\n",
      "Cost After 1700 iterations : nan\n",
      "Cost After 1800 iterations : nan\n",
      "Cost After 1900 iterations : nan\n",
      "Cost After 2000 iterations : nan\n",
      "train_acc : 100.0%\n",
      "test_acc : 65.99999999999999%\n"
     ]
    }
   ],
   "source": [
    "logistic_reg_model = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
